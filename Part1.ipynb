{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Part 1** of the project is divided into three sections:\n",
    "\n",
    "1- Feature Extraction (Using SIFT)\n",
    "\n",
    "2- Outlier Removal (Using RANSAC)\n",
    "\n",
    "3- Computing the Homographies (Using DLT)\n",
    "\n",
    "\n",
    "**pip install opencv-python**\n",
    "\n",
    "**pip install opencv-contrib-python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from numpy.linalg import eig\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the video\n",
    "capture = cv2.VideoCapture(os.path.abspath('trymefirst_lisbon.mp4'))\n",
    "while(capture.isOpened()):\n",
    "    ret, frame = capture.read()\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  ##press q if you want the video to stop \n",
    "        break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code **extracts SIFT features** from each frame of the input video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 128)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "capture = cv2.VideoCapture(os.path.abspath('trymefirst_lisbon.mp4'))\n",
    "kp_list = []\n",
    "sift_points = [] #nome a definir no config\n",
    "t = 0 \n",
    "sift = cv2.SIFT_create(5000) #number of sift points\n",
    "while True:\n",
    "    t = t + 1\n",
    "    if t == 5: break \n",
    "    success, frame = capture.read() #read the video\n",
    "    if success:\n",
    "        frame_points = []\n",
    "        gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY) #convert image to gray\n",
    "        kp, des = sift.detectAndCompute(gray,None) #kp = keypoint, des = descriptor\n",
    "        kp_list.append(kp)\n",
    "        frame_points = ([kp[0].pt[0],kp[0].pt[1]]+des[0].tolist())\n",
    "        for i in range(1,len(kp)):\n",
    "             list = ([kp[i].pt[0],kp[i].pt[1]]+des[i].tolist())\n",
    "             frame_points = np.column_stack((frame_points,list))  \n",
    "    sift_points.append(frame_points) #append everything into a list \n",
    "print(des.shape)\n",
    "print(len(sift_points))\n",
    "#The keypoint is a point of interest in the image, the descriptor is a vector that describes the image patch around the keypoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code **matches SIFT features** between the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Brute force method\n",
    "bf = cv2.BFMatcher(crossCheck=True) #crossCheck is set to true so that the match is symmetric\n",
    "all_matches = []\n",
    "match = []\n",
    "for s in range(len(sift_points)-1):\n",
    "    point_matches = []\n",
    "\n",
    "    des1 = (((sift_points[s])[2:,:])).astype('float32')  # descriptors of the first frame\n",
    "    des2 = (((sift_points[s+1])[2:,:])).astype('float32')  # descriptors of the second\n",
    "    des1 = np.reshape(des1,(np.shape(des1)[1],128))\n",
    "    des2 = np.reshape(des2,(np.shape(des2)[1],128))\n",
    "\n",
    "    if np.shape(des1)[0] > np.shape(des2)[0]:\n",
    "             des1 = des1[:-abs(np.shape(des1)[0]-np.shape(des2)[0]),:]  # we are removing the last points so that we have an equal amount of SIFT features between two frames\n",
    "    if np.shape(des1)[0] < np.shape(des2)[0]:\n",
    "             des2 = des2[:-abs(np.shape(des1)[0]-np.shape(des2)[0]),:]\n",
    "    matches = bf.match(des1,des2)  # an error occurs if two frames have different amounts of SIFT features\n",
    "    # try:\n",
    "    # except: \n",
    "    #       print('Error!')        \n",
    "             \n",
    "    for i in range(len(matches)):\n",
    "        match.append(matches)\n",
    "        point_matches.append([matches[i].queryIdx,matches[i].trainIdx])\n",
    "\n",
    "    all_matches.append(point_matches)\n",
    "#Feature detection: opencv\n",
    "#Matching : sklearn , numpy\n",
    "#RANSAC: numpy\n",
    "#Create Homography: numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code **computes the Homography** between the frames of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6427274690329576\n",
      "256563.54696650486\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "kp1 = kp_list[0]\n",
    "kp2 = kp_list[1]\n",
    "src_pts = np.float32([ kp1[q.queryIdx].pt for q in match[0] ]).reshape(-1,1,2)\n",
    "dst_pts = np.float32([ kp2[t.trainIdx].pt for t in match[1] ]).reshape(-1,1,2)\n",
    "src = np.reshape(src_pts,(np.shape(src_pts)[0],2))\n",
    "dst = np.reshape(dst_pts,(np.shape(dst_pts)[0],2))\n",
    "src = preprocessing.normalize(src)   #Normalization\n",
    "dst = preprocessing.normalize(dst)\n",
    "\n",
    "A = []\n",
    "for p, q in zip(src, dst):\n",
    "            x1 = p[0]\n",
    "            y1 = p[1]\n",
    "            x2 = q[0]\n",
    "            y2 = q[1]\n",
    "            A.append([-x1, -y1, -1, 0, 0, 0, x2*x1, x2*y1, x2])\n",
    "            A.append([0, 0, 0, -x1, -y1, -1, y2*x1, y2*y1, y2])\n",
    "_, _, Vt = np.linalg.svd(A, full_matrices=True)\n",
    "\n",
    "eigenvalue,eigenvector=eig(np.matmul(np.transpose(A),A))\n",
    "\n",
    "H = np.reshape(eigenvector[0],(3,3))\n",
    "print(np.linalg.cond(H))\n",
    "\n",
    "H2 =  Vt[-1,:].reshape(3, 3)\n",
    "print(np.linalg.cond(H2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11775348223449139"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = eigenvalue.argsort()[::-1]   \n",
    "eigenValues = eigenvalue[idx]\n",
    "eigenVectors = eigenvector[:,idx]\n",
    "eigenValues[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Comp_H(src,dst):\n",
    "        A = []\n",
    "        for p, q in zip(src, dst):\n",
    "            x1 = p[0]\n",
    "            y1 = p[1]\n",
    "            x2 = q[0]\n",
    "            y2 = q[1]\n",
    "            A.append([-x1, -y1, -1, 0, 0, 0, x2*x1, x2*y1, x2])\n",
    "            A.append([0, 0, 0, -x1, -y1, -1, y2*x1, y2*y1, y2])\n",
    "\n",
    "        eigenvalue,eigenvector=eig(np.matmul(np.transpose(A),A))\n",
    "        idx = eigenvalue.argsort()[::-1]   \n",
    "        eigenValues = eigenvalue[idx]\n",
    "        eigenVectors = eigenvector[:,idx]\n",
    "        eigenValues[-1]\n",
    "        #_, _, Vt = np.linalg.svd(A, full_matrices=True)\n",
    "        #x = Vt[-1]\n",
    "        x=eigenVectors[-1]\n",
    "        \n",
    "        H = x.reshape(3, -1) / x[-1]\n",
    "        return H\n",
    "\n",
    "def RANSAC(Comp_H,src,dst,iter,threshold):\n",
    "      best_homography = None\n",
    "      inliers = [0]\n",
    "      for t in range(iter):\n",
    "            sample_indices = np.random.choice(int(len(src)), size=8, replace=False)\n",
    "            #int(len(src)*0.1)\n",
    "            # Compute the Homography\n",
    "            H = Comp_H(src[sample_indices],dst[sample_indices])\n",
    "            inl = 0\n",
    "            for p, q in zip(src, dst):\n",
    "                x1 = p[0]\n",
    "                y1 = p[1]\n",
    "                x2 = q[0]\n",
    "                y2 = q[1]\n",
    "            # Transform the point using the estimated homography\n",
    "                transformed_point = np.dot(H, np.array([x1, y1, 1]))\n",
    "\n",
    "            # Normalize the transformed point\n",
    "                transformed_point /= transformed_point[2]\n",
    "\n",
    "            # Calculate the Euclidean distance between the transformed point and the actual point\n",
    "                distance = np.linalg.norm(np.array([x2, y2, 1]) - transformed_point)\n",
    "\n",
    "                if distance < threshold:\n",
    "                   inl += 1\n",
    "            if inl > inliers[0]:\n",
    "                 best_homography = H\n",
    "                 inliers[0] = inl\n",
    "      return best_homography, inliers[0] \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition: 4.908776732800521 inliers:  699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.03552178, 0.01145026, 0.30020634],\n",
       "       [0.78608688, 0.58811479, 0.11137041],\n",
       "       [0.95088638, 0.15565331, 1.        ]])"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H, inliers = RANSAC(Comp_H,src,dst,500,0.8)\n",
    "print('condition:',np.linalg.cond(H),'inliers: ', inliers)\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.07087813],\n",
       "       [0.87372768],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picture2 = np.reshape(np.array([552,59,1]),(3,1))\n",
    "picture1 = np.reshape(np.array([549,56,1]),(3,1))\n",
    "pic_h = np.matmul(H,picture1)\n",
    "pic_h/pic_h[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Zone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1183369800502505"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp1 = kp_list[0]\n",
    "kp2 = kp_list[1]\n",
    "src_pts = np.float32([ kp1[all_matches[0][i][0]].pt for i in range(len(all_matches[0])) ]).reshape(-1,1,2)\n",
    "dst_pts = np.float32([ kp2[all_matches[0][i][1]].pt for i in range(len(all_matches[0])) ]).reshape(-1,1,2)\n",
    "M2, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "np.linalg.cond(M2)\n",
    "\n",
    "kp1 = kp_list[0]\n",
    "kp2 = kp_list[1]\n",
    "src_pts = np.float32([ kp1[q.queryIdx].pt for q in match[0] ]).reshape(-1,1,2)\n",
    "dst_pts = np.float32([ kp2[t.trainIdx].pt for t in match[1] ]).reshape(-1,1,2)\n",
    "M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "np.linalg.cond(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[552.38505024],\n",
       "       [ 60.09752571],\n",
       "       [  1.        ]])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic_h2 = np.matmul(M,picture2)\n",
    "pic_h2/pic_h2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67711165.49974936"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getPerspectiveTransform(src, dst):\n",
    "    if len(src) == len(dst):\n",
    "        # Make homogeneous coordiates if necessary\n",
    "        if src.shape[1] == 2:\n",
    "            src = np.hstack((src, np.ones((len(src), 1), dtype=src.dtype)))\n",
    "        if dst.shape[1] == 2:\n",
    "            dst = np.hstack((dst, np.ones((len(dst), 1), dtype=dst.dtype)))\n",
    "\n",
    "        # Solve 'Ax = 0'\n",
    "        A = []\n",
    "        for p, q in zip(src, dst):\n",
    "            A.append([0, 0, 0, q[2]*p[0], q[2]*p[1], q[2]*p[2], -q[1]*p[0], -q[1]*p[1], -q[1]*p[2]])\n",
    "            A.append([q[2]*p[0], q[2]*p[1], q[2]*p[2], 0, 0, 0, -q[0]*p[0], -q[0]*p[1], -q[0]*p[2]])\n",
    "\n",
    "        eigenvalue,eigenvector=eig(np.matmul(np.transpose(A),A))\n",
    "        #_, _, Vt = np.linalg.svd(A, full_matrices=True)\n",
    "        #x = Vt[-1]\n",
    "        x = \n",
    "\n",
    "        # Reorganize `x` as a matrix\n",
    "        H = x.reshape(3, -1) / x[-1] # Normalize the last element as 1\n",
    "        return H\n",
    "    \n",
    "\n",
    "H_slides = getPerspectiveTransform(np.reshape(src_pts,(np.shape(src_pts)[0],2)), np.reshape(dst_pts,(np.shape(dst_pts)[0],2)))\n",
    "np.linalg.cond(H_slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78435055],\n",
       "       [0.61151436],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picture2 = np.reshape(np.array([552,59,1]),(3,1))\n",
    "picture1 = np.reshape(np.array([549,56,1]),(3,1))\n",
    "pic_h = np.matmul(H2,picture1)\n",
    "pic_h/pic_h[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[492.55113247],\n",
       "       [293.19723376],\n",
       "       [  1.        ]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic_h3 = np.matmul(H_slides,picture2)\n",
    "pic_h3/pic_h3[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_point(event,x,y,flags,param):\n",
    "    global ix,iy\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK: # captures left button double-click\n",
    "        print('x = %d, y = %d'%(x, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(os.path.abspath('trymefirst_lisbon.mp4'))\n",
    "framenr = 0 \n",
    "list_points = []\n",
    "while True:\n",
    "    success, frame = capture.read()\n",
    "    if success:\n",
    "        print('Current Frame!')\n",
    "        cv2.namedWindow('frame')\n",
    "        cv2.setMouseCallback('frame', select_point)\n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(0) & 0xFF == ord('q'):  ##press q if you want the video to stop \n",
    "             break\n",
    "        key = cv2.waitKey(0) & 0xFF == ord('k')\n",
    "        \n",
    "        print('New Frame!')\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
