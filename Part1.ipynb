{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Part 1** of the project is divided into three sections:\n",
    "\n",
    "1- Feature Extraction (Using SIFT)\n",
    "\n",
    "2- Outlier Removal (Using RANSAC)\n",
    "\n",
    "3- Computing the Homographies (Using DLT)\n",
    "\n",
    "\n",
    "**pip install opencv-python**\n",
    "\n",
    "**pip install opencv-contrib-python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from numpy.linalg import eig\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the video\n",
    "capture = cv2.VideoCapture(os.path.abspath('Video/trymefirst_lisbon.mp4')) \n",
    "while(capture.isOpened()):\n",
    "    ret, frame = capture.read()\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  ##press q if you want the video to stop \n",
    "        break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code **extracts SIFT features** from each frame of the input video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "capture = cv2.VideoCapture(os.path.abspath('Video/trymefirst_lisbon.mp4'))\n",
    "kp_list = []\n",
    "sift_points = [] #nome a definir no config\n",
    "t = 0 \n",
    "sift = cv2.SIFT_create(5000) #number of sift points\n",
    "while True:\n",
    "    t = t + 1\n",
    "    if t == 5: break \n",
    "    success, frame = capture.read() #read the video\n",
    "    if success:\n",
    "        frame_points = []\n",
    "        gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY) #convert image to gray\n",
    "        kp, des = sift.detectAndCompute(gray,None) #kp = keypoint, des = descriptor\n",
    "        kp_list.append(kp)\n",
    "        frame_points = ([kp[0].pt[0],kp[0].pt[1]]+des[0].tolist())\n",
    "        for i in range(1,len(kp)):\n",
    "             list = ([kp[i].pt[0],kp[i].pt[1]]+des[i].tolist())\n",
    "             frame_points = np.column_stack((frame_points,list))  \n",
    "        sift_points.append(frame_points) #append everything into a list \n",
    "#print(des.shape)\n",
    "#print(len(sift_points))\n",
    "#The keypoint is a point of interest in the image, the descriptor is a vector that describes the image patch around the keypoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code **matches SIFT features** between the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Brute force method\n",
    "bf = cv2.BFMatcher(crossCheck=True) #crossCheck is set to true so that the match is symmetric\n",
    "all_matches = []\n",
    "match = []\n",
    "for s in range(len(sift_points)-1):\n",
    "    point_matches = []\n",
    "\n",
    "    des1 = (((sift_points[s])[2:,:])).astype('float32')  # descriptors of the first frame\n",
    "    des2 = (((sift_points[s+1])[2:,:])).astype('float32')  # descriptors of the second\n",
    "    des1 = np.reshape(des1,(np.shape(des1)[1],128))\n",
    "    des2 = np.reshape(des2,(np.shape(des2)[1],128))\n",
    "\n",
    "    if np.shape(des1)[0] > np.shape(des2)[0]:\n",
    "             des1 = des1[:-abs(np.shape(des1)[0]-np.shape(des2)[0]),:]  # we are removing the last points so that we have an equal amount of SIFT features between two frames\n",
    "    if np.shape(des1)[0] < np.shape(des2)[0]:\n",
    "             des2 = des2[:-abs(np.shape(des1)[0]-np.shape(des2)[0]),:]\n",
    "    matches = bf.match(des1,des2)  # an error occurs if two frames have different amounts of SIFT features\n",
    "    # try:\n",
    "    # except: \n",
    "    #       print('Error!')        \n",
    "             \n",
    "    for i in range(len(matches)):\n",
    "        match.append(matches)\n",
    "        point_matches.append([matches[i].queryIdx,matches[i].trainIdx])\n",
    "\n",
    "    all_matches.append(point_matches)\n",
    "#Feature detection: opencv\n",
    "#Matching : sklearn , numpy\n",
    "#RANSAC: numpy\n",
    "#Create Homography: numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code **computes the Homography** between the frames of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalize(points):\n",
    "    mean = np.mean(points, axis=0)\n",
    "    std_dev = np.std(points)\n",
    "    T = np.array([[std_dev, 0, mean[0]], [0, std_dev, mean[1]], [0, 0, 1]])\n",
    "    T_inv = np.linalg.inv(T)\n",
    "    normalized_points = np.dot(T_inv, np.append(points, np.ones((points.shape[0], 1)), axis=1).T).T\n",
    "    return normalized_points, T\n",
    "\n",
    "def construct_matrix_A(points1, points2):\n",
    "    A = []\n",
    "    for i in range(points1.shape[0]):\n",
    "        x1, y1 = points1[i, 0], points1[i, 1]\n",
    "        x2, y2 = points2[i, 0], points2[i, 1]\n",
    "        A.append([-x1, -y1, -1, 0, 0, 0, x2*x1, x2*y1, x2])\n",
    "        A.append([0, 0, 0, -x1, -y1, -1, y2*x1, y2*y1, y2])\n",
    "    return np.array(A)\n",
    "\n",
    "def compute_homography(points1, points2):\n",
    "    points1_norm, T1 = normalize(points1)\n",
    "    points2_norm, T2 = normalize(points2)\n",
    "    A = construct_matrix_A(points1_norm, points2_norm)\n",
    "    _, _, V = np.linalg.svd(A)\n",
    "    H = V[-1].reshape(3, 3)\n",
    "    H = np.dot(np.linalg.inv(T2), np.dot(H, T1))\n",
    "    return H / H[2, 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_points(points):\n",
    "    # Normalize points to have zero mean and unit variance\n",
    "    mean = np.mean(points, axis=0)\n",
    "    std = np.std(points, axis=0)\n",
    "    normalized_points = (points - mean) / std\n",
    "    return normalized_points, mean, std\n",
    "\n",
    "\n",
    "def denormalize_homography(H, mean_src, std_src, mean_dst, std_dst):\n",
    "    # Denormalize the homography matrix based on mean and standard deviation\n",
    "   # T_src = np.array([[1 / std_src[0], 0, -mean_src[0] / std_src[0]],\n",
    "            #          [0, 1 / std_src[1], -mean_src[1] / std_src[1]],\n",
    "            #          [0, 0, 1]])\n",
    "\n",
    "   # T_dst = np.array([[1 / std_dst[0], 0, -mean_dst[0] / std_dst[0]],\n",
    "   #                   [0, 1 / std_dst[1], -mean_dst[1] / std_dst[1]],\n",
    "   #                   [0, 0, 1]])\n",
    "    T_src = np.array([[std_src[0], 0, mean_src[0]], [0, std_src[1], mean_src[1]], [0, 0, 1]])\n",
    "    T_dst = np.array([[std_dst[0], 0, mean_dst[0]], [0, std_src[1], mean_dst[1]], [0, 0, 1]])\n",
    "\n",
    "    Homography = np.dot(np.linalg.inv(T_dst), np.dot(H, T_src))\n",
    "    \n",
    "    return  Homography\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "kp1 = kp_list[0]\n",
    "kp2 = kp_list[1]\n",
    "src_pts = np.float32([ kp1[q.queryIdx].pt for q in match[0] ]).reshape(-1,1,2)\n",
    "dst_pts = np.float32([ kp2[t.trainIdx].pt for t in match[1] ]).reshape(-1,1,2)\n",
    "src = np.reshape(src_pts,(np.shape(src_pts)[0],2))\n",
    "dst = np.reshape(dst_pts,(np.shape(dst_pts)[0],2))\n",
    "\n",
    "\n",
    "src_pts_normalized, mean_src, std_src = normalize_points(src)\n",
    "dst_pts_normalized, mean_dst, std_dst = normalize_points(dst)\n",
    "#src = preprocessing.normalize(src)   #Normalization\n",
    "#dst = preprocessing.normalize(dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Comp_H(src,dst):\n",
    "        A = []\n",
    "        for p, q in zip(src, dst):\n",
    "            x1 = p[0]\n",
    "            y1 = p[1]\n",
    "            x2 = q[0]\n",
    "            y2 = q[1]\n",
    "            A.append([-x1, -y1, -1, 0, 0, 0, x2*x1, x2*y1, x2])\n",
    "            A.append([0, 0, 0, -x1, -y1, -1, y2*x1, y2*y1, y2])\n",
    "\n",
    "        _, _, Vt = np.linalg.svd(A, full_matrices=True)\n",
    "        x = Vt[-1]\n",
    "        homography = x.reshape(3, -1) / x[-1]\n",
    "        return homography\n",
    "\n",
    "def RANSAC(Comp_H,src,dst,iter,threshold):\n",
    "      best_homography = None\n",
    "      inliers = [0]\n",
    "      for t in range(iter):\n",
    "            sample_indices = np.random.choice(int(len(src)), size=4, replace=False)\n",
    "            # Compute the Homography\n",
    "            H = Comp_H(src[sample_indices],dst[sample_indices])\n",
    "            #H = denormalize_homography(homography, mean_src, std_src, mean_dst, std_dst)\n",
    "            inl = 0\n",
    "            for p, q in zip(src, dst):\n",
    "                x1 = p[0]\n",
    "                y1 = p[1]\n",
    "                x2 = q[0]\n",
    "                y2 = q[1]\n",
    "            # Transform the point using the estimated homography\n",
    "                transformed_point = np.dot(H, np.array([x1, y1, 1]))\n",
    "\n",
    "            # Normalize the transformed point\n",
    "                transformed_point /= transformed_point[2]\n",
    "\n",
    "            # Calculate the Euclidean distance between the transformed point and the actual point\n",
    "                distance = np.linalg.norm(np.array([x2, y2, 1]) - transformed_point)\n",
    "                if distance < threshold:\n",
    "                   inl += 1\n",
    "            if inl > inliers[0]:\n",
    "                 best_homography = H\n",
    "                 inliers[0] = inl\n",
    "      return best_homography, inliers[0] \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition: 1733.4008792564298 inliers:  60\n",
      "the error is: \n",
      " [[-217.55780203]\n",
      " [ 129.59353309]\n",
      " [   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "H, inliers = RANSAC(Comp_H,src,dst,143,30)\n",
    "print('condition:',np.linalg.cond(H), 'inliers: ', inliers )\n",
    "picture2 = np.reshape(np.array([552,59,1]),(3,1))\n",
    "picture1 = np.reshape(np.array([549,56,1]),(3,1))\n",
    "pic_h = np.matmul(H,picture1)\n",
    "print('the error is: \\n', pic_h/pic_h[2]-picture1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Zone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1183369800502505"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#src_pts = np.float32([ kp1[all_matches[0][i][0]].pt for i in range(len(all_matches[0])) ]).reshape(-1,1,2)\n",
    "#dst_pts = np.float32([ kp2[all_matches[0][i][1]].pt for i in range(len(all_matches[0])) ]).reshape(-1,1,2)\n",
    "#M2, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "#np.linalg.cond(M2)\n",
    "\n",
    "kp1 = kp_list[0]\n",
    "kp2 = kp_list[1]\n",
    "src_pts = np.float32([ kp1[q.queryIdx].pt for q in match[0] ]).reshape(-1,1,2)\n",
    "dst_pts = np.float32([ kp2[t.trainIdx].pt for t in match[1] ]).reshape(-1,1,2)\n",
    "M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "np.linalg.cond(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-286.19830942],\n",
       "       [ -61.0945108 ],\n",
       "       [   1.        ]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic_h2 = np.matmul(M,picture2)\n",
    "pic_h2/pic_h2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67711165.49974936"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getPerspectiveTransform(src, dst):\n",
    "    if len(src) == len(dst):\n",
    "        # Make homogeneous coordiates if necessary\n",
    "        if src.shape[1] == 2:\n",
    "            src = np.hstack((src, np.ones((len(src), 1), dtype=src.dtype)))\n",
    "        if dst.shape[1] == 2:\n",
    "            dst = np.hstack((dst, np.ones((len(dst), 1), dtype=dst.dtype)))\n",
    "\n",
    "        # Solve 'Ax = 0'\n",
    "        A = []\n",
    "        for p, q in zip(src, dst):\n",
    "            A.append([0, 0, 0, q[2]*p[0], q[2]*p[1], q[2]*p[2], -q[1]*p[0], -q[1]*p[1], -q[1]*p[2]])\n",
    "            A.append([q[2]*p[0], q[2]*p[1], q[2]*p[2], 0, 0, 0, -q[0]*p[0], -q[0]*p[1], -q[0]*p[2]])\n",
    "\n",
    "        eigenvalue,eigenvector=eig(np.matmul(np.transpose(A),A))\n",
    "        _, _, Vt = np.linalg.svd(A, full_matrices=True)\n",
    "        x = Vt[-1]\n",
    "         \n",
    "\n",
    "        # Reorganize `x` as a matrix\n",
    "        H = x.reshape(3, -1) / x[-1] # Normalize the last element as 1\n",
    "        return H\n",
    "    \n",
    "\n",
    "H_slides = getPerspectiveTransform(np.reshape(src_pts,(np.shape(src_pts)[0],2)), np.reshape(dst_pts,(np.shape(dst_pts)[0],2)))\n",
    "np.linalg.cond(H_slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[492.63500599],\n",
       "       [293.28418155],\n",
       "       [  1.        ]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picture2 = np.reshape(np.array([552,59,1]),(3,1))\n",
    "picture1 = np.reshape(np.array([549,56,1]),(3,1))\n",
    "pic_h = np.matmul(H_slides,picture1)\n",
    "pic_h/pic_h[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[492.55113247],\n",
       "       [293.19723376],\n",
       "       [  1.        ]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic_h3 = np.matmul(H_slides,picture2)\n",
    "pic_h3/pic_h3[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_point(event,x,y,flags,param):\n",
    "    global ix,iy\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK: # captures left button double-click\n",
    "        print('x = %d, y = %d'%(x, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(os.path.abspath('trymefirst_lisbon.mp4'))\n",
    "framenr = 0 \n",
    "list_points = []\n",
    "while True:\n",
    "    success, frame = capture.read()\n",
    "    if success:\n",
    "        print('Current Frame!')\n",
    "        cv2.namedWindow('frame')\n",
    "        cv2.setMouseCallback('frame', select_point)\n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(0) & 0xFF == ord('q'):  ##press q if you want the video to stop \n",
    "             break\n",
    "        key = cv2.waitKey(0) & 0xFF == ord('k')\n",
    "        \n",
    "        print('New Frame!')\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
