{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Part 1** of the project is divided into three sections:\n",
    "\n",
    "1- Feature Extraction (Using SIFT)\n",
    "\n",
    "2- Outlier Removal (Using RANSAC)\n",
    "\n",
    "3- Computing the Homographies (Using DLT)\n",
    "\n",
    "\n",
    "**pip install opencv-python**\n",
    "\n",
    "**pip install opencv-contrib-python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from numpy.linalg import eig\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the video\n",
    "capture = cv2.VideoCapture(os.path.abspath('trymefirst_lisbon.mp4'))\n",
    "while(capture.isOpened()):\n",
    "    ret, frame = capture.read()\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  ##press q if you want the video to stop \n",
    "        break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code **extracts SIFT features** from each frame of the input video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "capture = cv2.VideoCapture(os.path.abspath('trymefirst_lisbon.mp4'))\n",
    "\n",
    "sift_points = [] #nome a definir no config\n",
    "t = 0 \n",
    "sift = cv2.SIFT_create(100) #number of sift points\n",
    "while True:\n",
    "    t = t + 1\n",
    "    if t == 5: break \n",
    "    success, frame = capture.read()\n",
    "    if success:\n",
    "        frame_points = []\n",
    "        gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        kp, des = sift.detectAndCompute(gray,None)\n",
    "        frame_points = ([kp[0].pt[0],kp[0].pt[1]]+des[0].tolist())\n",
    "        for i in range(1,len(kp)):\n",
    "             list = ([kp[i].pt[0],kp[i].pt[1]]+des[i].tolist())\n",
    "             frame_points = np.column_stack((frame_points,list))  \n",
    "    sift_points.append(frame_points) #append everything into a list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code **matches SIFT features** between the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Brute force method\n",
    "bf = cv2.BFMatcher(crossCheck=True)\n",
    "all_matches = []\n",
    "\n",
    "for s in range(len(sift_points)-1):\n",
    "    point_matches = []\n",
    "\n",
    "    des1 = (((sift_points[s])[2:,:])).astype('float32')  # descriptors of the first frame\n",
    "    des2 = (((sift_points[s+1])[2:,:])).astype('float32')  # descriptors of the second\n",
    "    des1 = np.reshape(des1,(np.shape(des1)[1],128))\n",
    "    des2 = np.reshape(des2,(np.shape(des2)[1],128))\n",
    "\n",
    "    if np.shape(des1)[0] > np.shape(des2)[0]:\n",
    "             des1 = des1[:-abs(np.shape(des1)[0]-np.shape(des2)[0]),:]  # we are removing the last points so that we have an equal amount of SIFT features between two frames\n",
    "    if np.shape(des1)[0] < np.shape(des2)[0]:\n",
    "             des2 = des2[:-abs(np.shape(des1)[0]-np.shape(des2)[0]),:]\n",
    "    try:\n",
    "        matches = bf.match(des1,des2)  # an error occurs if two frames have different amounts of SIFT features\n",
    "    except: \n",
    "          print('Error!')        \n",
    "             \n",
    "    for i in range(len(matches)):\n",
    "       \n",
    "        point_matches.append([matches[i].queryIdx,matches[i].trainIdx])\n",
    "    all_matches.append(point_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code **computes the Homography** between the frames of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = sift_points[0]\n",
    "image2 = sift_points[1]\n",
    "A=[]\n",
    "for i in range(len(all_matches[0])):\n",
    "\n",
    "   x1,y1 = image1[0,all_matches[0][i][0]],image1[1,all_matches[0][i][1]]\n",
    "   x2,y2 = image1[0,all_matches[0][i][0]],image1[1,all_matches[0][i][1]]\n",
    "   A.append([-x1, -y1, -1, 0, 0, 0, x2*x1, x2*y1, x2])\n",
    "   A.append([0, 0, 0, -x1, -y1, -1, y2*x1, y2*y1, y2])\n",
    "\n",
    "U, S, Vh = np.linalg.svd(A)\n",
    "eigenvalue,eigenvector=eig(np.matmul(np.transpose(A),A))\n",
    "H = np.reshape(eigenvector[0],(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4003532494037625"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.cond(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
